{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "# on2vec: Ontology Embeddings Demo\n\nThis notebook demonstrates how to use the on2vec toolkit to generate embeddings from OWL ontologies.\n\nWe'll use the Cardiovascular Disease Ontology (CVDO) as an example - a structured vocabulary for cardiovascular disease concepts, risk factors, and related terms.\n\n## Overview\n\n1. **Download**: Get the Cardiovascular Disease Ontology OWL file\n2. **Train**: Create a GNN model from the ontology structure \n3. **Embed**: Generate embedding vectors for all concepts\n4. **Analyze**: Explore the embeddings with metadata and vector operations\n5. **Export**: Convert to different formats for downstream analysis"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "First, let's install the notebook dependencies and import required modules:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install notebook dependencies if needed\n",
    "import sys\n",
    "import subprocess\n",
    "\n",
    "def install_if_missing(package):\n",
    "    try:\n",
    "        __import__(package)\n",
    "    except ImportError:\n",
    "        subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", package])\n",
    "\n",
    "install_if_missing(\"requests\")\n",
    "install_if_missing(\"IPython\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "import os\nimport sys\nimport requests\nimport numpy as np\nfrom pathlib import Path\nfrom IPython.display import display, Markdown, HTML\n\n# Add the on2vec package to the path\nsys.path.insert(0, '.')\n\n# Import on2vec modules\nfrom on2vec import (\n    train_ontology_embeddings,\n    embed_ontology_with_model,\n    inspect_parquet_metadata,\n    load_embeddings_as_dataframe,\n    convert_parquet_to_csv,\n    add_embedding_vectors,\n    subtract_embedding_vectors,\n    get_embedding_vector\n)\n\nprint(\"‚úÖ Imports successful!\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## Step 1: Download the Cardiovascular Disease Ontology\n\nThe Cardiovascular Disease Ontology (CVDO) is a structured vocabulary for cardiovascular disease concepts. Let's download it:"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "def download_owl_file(url, filename):\n    \"\"\"Download an OWL file from URL with progress indication.\"\"\"\n    if os.path.exists(filename):\n        print(f\"üìÅ {filename} already exists (size: {os.path.getsize(filename):,} bytes)\")\n        return filename\n    \n    print(f\"‚¨áÔ∏è  Downloading {filename} from {url}\")\n    \n    try:\n        response = requests.get(url, stream=True)\n        response.raise_for_status()\n        \n        total_size = int(response.headers.get('content-length', 0))\n        \n        with open(filename, 'wb') as f:\n            downloaded = 0\n            for chunk in response.iter_content(chunk_size=8192):\n                if chunk:\n                    f.write(chunk)\n                    downloaded += len(chunk)\n                    if total_size > 0:\n                        percent = (downloaded / total_size) * 100\n                        print(f\"\\rProgress: {percent:.1f}% ({downloaded:,}/{total_size:,} bytes)\", end=\"\")\n        \n        print(f\"\\n‚úÖ Downloaded {filename} ({os.path.getsize(filename):,} bytes)\")\n        return filename\n        \n    except Exception as e:\n        print(f\"‚ùå Error downloading {filename}: {e}\")\n        return None\n\n# Download the Cardiovascular Disease Ontology\nowl_url = \"http://purl.obolibrary.org/obo/cvdo.owl\"\nowl_file = \"cvdo.owl\"\n\ndownloaded_file = download_owl_file(owl_url, owl_file)\n\nif downloaded_file:\n    display(Markdown(f\"**üìä Cardiovascular Disease Ontology downloaded:** `{downloaded_file}`\"))\n    display(Markdown(f\"**üìè File size:** {os.path.getsize(downloaded_file):,} bytes ({os.path.getsize(downloaded_file)/(1024*1024):.1f} MB)\"))\nelse:\n    display(Markdown(\"‚ùå **Failed to download ontology file!**\"))"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## Step 2: Train a Model\n\nNow let's train a Graph Neural Network on the cardiovascular disease ontology structure. We'll use a smaller model for demonstration purposes:"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "if downloaded_file:\n    print(\"üöÄ Training GNN model on Cardiovascular Disease Ontology...\")\n    print(\"This may take a few minutes depending on ontology size.\")\n    \n    try:\n        # Train the model using the high-level function\n        training_result = train_ontology_embeddings(\n            owl_file=downloaded_file,\n            model_output='cvdo_model.pt',\n            model_type='gcn',\n            hidden_dim=32,      # Smaller for demo\n            out_dim=16,         # 16-dimensional embeddings\n            epochs=20,          # Fewer epochs for demo\n            loss_fn_name='triplet'\n        )\n        \n        display(Markdown(f\"### ‚úÖ Training Complete!\"))\n        display(Markdown(f\"**Model saved to:** `{training_result['model_path']}`\"))\n        display(Markdown(f\"**Training time:** {training_result.get('training_time', 'N/A')} seconds\"))\n        \n        # Display model info\n        checkpoint = training_result.get('checkpoint', {})\n        model_info = checkpoint.get('model_config', {})\n        \n        info_html = f\"\"\"\n        <div style=\"background-color: #f0f8ff; padding: 15px; border-radius: 5px; border-left: 4px solid #0066cc;\">\n        <h4>ü§ñ Model Configuration</h4>\n        <ul>\n            <li><strong>Architecture:</strong> {model_info.get('model_type', 'GCN').upper()}</li>\n            <li><strong>Hidden Dimensions:</strong> {model_info.get('hidden_dim', 32)}</li>\n            <li><strong>Output Dimensions:</strong> {model_info.get('out_dim', 16)}</li>\n            <li><strong>Loss Function:</strong> {model_info.get('loss_function', 'triplet')}</li>\n            <li><strong>Epochs:</strong> {model_info.get('epochs', 20)}</li>\n        </ul>\n        </div>\n        \"\"\"\n        display(HTML(info_html))\n        \n        model_file = training_result['model_path']\n        \n    except Exception as e:\n        display(Markdown(f\"‚ùå **Training failed:** {e}\"))\n        model_file = None\nelse:\n    display(Markdown(\"‚è≠Ô∏è **Skipping training** - no ontology file available\"))\n    model_file = None"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Generate Embeddings\n",
    "\n",
    "With our trained model, let's generate embeddings for all concepts in the ontology:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "if model_file and downloaded_file:\n    print(\"üìä Generating embeddings for all concepts...\")\n    \n    embedding_file = \"cvdo_embeddings.parquet\"\n    \n    try:\n        # Generate embeddings using the trained model\n        embedding_result = embed_ontology_with_model(\n            model_path=model_file,\n            owl_file=downloaded_file,\n            output_file=embedding_file\n        )\n        \n        display(Markdown(f\"### ‚úÖ Embeddings Generated!\"))\n        display(Markdown(f\"**File:** `{embedding_file}`\"))\n        display(Markdown(f\"**Embeddings:** {len(embedding_result['node_ids']):,} concept vectors\"))\n        display(Markdown(f\"**Dimensions:** {embedding_result['embeddings'].shape[1]} per vector\"))\n        \n        # Display alignment info\n        alignment = embedding_result.get('alignment_info', {})\n        \n        alignment_html = f\"\"\"\n        <div style=\"background-color: #f0fff0; padding: 15px; border-radius: 5px; border-left: 4px solid #00cc66;\">\n        <h4>üîó Ontology Alignment</h4>\n        <ul>\n            <li><strong>Aligned Classes:</strong> {alignment.get('aligned_classes', 0):,}</li>\n            <li><strong>Total Classes:</strong> {alignment.get('total_classes', 0):,}</li>\n            <li><strong>Alignment Ratio:</strong> {alignment.get('alignment_ratio', 0):.1%}</li>\n        </ul>\n        </div>\n        \"\"\"\n        display(HTML(alignment_html))\n        \n    except Exception as e:\n        display(Markdown(f\"‚ùå **Embedding generation failed:** {e}\"))\n        embedding_file = None\nelse:\n    display(Markdown(\"‚è≠Ô∏è **Skipping embedding generation** - no trained model available\"))\n    embedding_file = None"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Inspect Embeddings Metadata\n",
    "\n",
    "Let's examine the metadata stored in our embedding file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if embedding_file and os.path.exists(embedding_file):\n",
    "    print(\"üîç Inspecting embedding file metadata:\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    # Use our inspect function to show metadata\n",
    "    metadata = inspect_parquet_metadata(embedding_file)\n",
    "    \n",
    "    # Also show file size info\n",
    "    file_size = os.path.getsize(embedding_file)\n",
    "    display(Markdown(f\"**üíæ File Size:** {file_size:,} bytes ({file_size/(1024*1024):.2f} MB)\"))\n",
    "else:\n",
    "    display(Markdown(\"‚è≠Ô∏è **No embedding file to inspect**\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Load and Explore Embeddings\n",
    "\n",
    "Let's load the embeddings as a DataFrame for analysis:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if embedding_file and os.path.exists(embedding_file):\n",
    "    # Load embeddings as DataFrame\n",
    "    df, metadata = load_embeddings_as_dataframe(embedding_file, return_metadata=True)\n",
    "    \n",
    "    display(Markdown(f\"### üìä DataFrame Overview\"))\n",
    "    display(Markdown(f\"**Shape:** {df.shape[0]:,} rows √ó {df.shape[1]} columns\"))\n",
    "    \n",
    "    # Show first few rows\n",
    "    display(Markdown(\"### üîé First 10 Concept IDs:\"))\n",
    "    \n",
    "    for i, node_id in enumerate(df['node_id'].head(10).to_list(), 1):\n",
    "        # Make URIs more readable by showing just the end part\n",
    "        short_id = node_id.split('/')[-1] if '/' in node_id else node_id\n",
    "        display(Markdown(f\"**{i:2d}.** `{short_id}` ‚Üí `{node_id}`\"))\n",
    "    \n",
    "    if len(df) > 10:\n",
    "        display(Markdown(f\"... and {len(df) - 10:,} more concepts\"))\n",
    "    \n",
    "    # Show embedding statistics\n",
    "    sample_embedding = np.array(df['embedding'][0])\n",
    "    display(Markdown(f\"### üìà Embedding Statistics\"))\n",
    "    display(Markdown(f\"**Vector dimensions:** {len(sample_embedding)}\"))\n",
    "    display(Markdown(f\"**Sample vector range:** [{sample_embedding.min():.3f}, {sample_embedding.max():.3f}]\"))\n",
    "    display(Markdown(f\"**Sample vector mean:** {sample_embedding.mean():.3f}\"))\n",
    "    \n",
    "else:\n",
    "    display(Markdown(\"‚è≠Ô∏è **No embedding file to analyze**\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: Vector Operations\n",
    "\n",
    "Let's demonstrate vector arithmetic operations on embeddings:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if embedding_file and os.path.exists(embedding_file):\n",
    "    # Get first few concept IDs for demonstration\n",
    "    df = load_embeddings_as_dataframe(embedding_file)\n",
    "    concept_ids = df['node_id'].head(5).to_list()\n",
    "    \n",
    "    if len(concept_ids) >= 3:\n",
    "        concept1 = concept_ids[0]\n",
    "        concept2 = concept_ids[1]\n",
    "        concept3 = concept_ids[2]\n",
    "        \n",
    "        display(Markdown(\"### ‚ûï Vector Addition\"))\n",
    "        display(Markdown(f\"Computing: `{concept1.split('/')[-1]}` + `{concept2.split('/')[-1]}`\"))\n",
    "        \n",
    "        # Add two vectors\n",
    "        try:\n",
    "            sum_vector = add_embedding_vectors(embedding_file, concept1, embedding_file, concept2)\n",
    "            display(Markdown(f\"**Result:** {len(sum_vector)}-dimensional vector\"))\n",
    "            display(Markdown(f\"**Range:** [{sum_vector.min():.3f}, {sum_vector.max():.3f}]\"))\n",
    "            display(Markdown(f\"**Mean:** {sum_vector.mean():.3f}\"))\n",
    "        except Exception as e:\n",
    "            display(Markdown(f\"‚ùå Addition failed: {e}\"))\n",
    "        \n",
    "        display(Markdown(\"### ‚ûñ Vector Subtraction\"))\n",
    "        display(Markdown(f\"Computing: `{concept1.split('/')[-1]}` - `{concept3.split('/')[-1]}`\"))\n",
    "        \n",
    "        # Subtract two vectors\n",
    "        try:\n",
    "            diff_vector = subtract_embedding_vectors(embedding_file, concept1, embedding_file, concept3)\n",
    "            display(Markdown(f\"**Result:** {len(diff_vector)}-dimensional vector\"))\n",
    "            display(Markdown(f\"**Range:** [{diff_vector.min():.3f}, {diff_vector.max():.3f}]\"))\n",
    "            display(Markdown(f\"**Mean:** {diff_vector.mean():.3f}\"))\n",
    "        except Exception as e:\n",
    "            display(Markdown(f\"‚ùå Subtraction failed: {e}\"))\n",
    "        \n",
    "        display(Markdown(\"### üéØ Individual Vector Retrieval\"))\n",
    "        display(Markdown(f\"Getting embedding for: `{concept1.split('/')[-1]}`\"))\n",
    "        \n",
    "        try:\n",
    "            vector = get_embedding_vector(embedding_file, concept1)\n",
    "            display(Markdown(f\"**Dimensions:** {len(vector)}\"))\n",
    "            display(Markdown(f\"**First 5 values:** {vector[:5].tolist()}\"))\n",
    "            display(Markdown(f\"**Last 5 values:** {vector[-5:].tolist()}\"))\n",
    "        except Exception as e:\n",
    "            display(Markdown(f\"‚ùå Vector retrieval failed: {e}\"))\n",
    "    \n",
    "    else:\n",
    "        display(Markdown(\"‚ö†Ô∏è **Not enough concepts for vector operations demo**\"))\n",
    "else:\n",
    "    display(Markdown(\"‚è≠Ô∏è **No embedding file for vector operations**\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 7: Format Conversion\n",
    "\n",
    "Finally, let's convert our embeddings to CSV format for use with other tools:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if embedding_file and os.path.exists(embedding_file):\n",
    "    display(Markdown(\"### üìÅ Converting to CSV Format\"))\n",
    "    \n",
    "    try:\n",
    "        csv_file = convert_parquet_to_csv(embedding_file)\n",
    "        \n",
    "        csv_size = os.path.getsize(csv_file)\n",
    "        parquet_size = os.path.getsize(embedding_file)\n",
    "        \n",
    "        display(Markdown(f\"‚úÖ **Conversion complete!**\"))\n",
    "        display(Markdown(f\"**CSV file:** `{csv_file}`\"))\n",
    "        display(Markdown(f\"**CSV size:** {csv_size:,} bytes ({csv_size/(1024*1024):.2f} MB)\"))\n",
    "        display(Markdown(f\"**Parquet size:** {parquet_size:,} bytes ({parquet_size/(1024*1024):.2f} MB)\"))\n",
    "        display(Markdown(f\"**Size ratio:** CSV is {csv_size/parquet_size:.1f}x larger than Parquet\"))\n",
    "        \n",
    "        # Show CSV preview\n",
    "        display(Markdown(\"### üëÄ CSV Preview (first 3 lines):\"))\n",
    "        \n",
    "        try:\n",
    "            with open(csv_file, 'r') as f:\n",
    "                lines = [f.readline().strip() for _ in range(3)]\n",
    "            \n",
    "            for i, line in enumerate(lines, 1):\n",
    "                # Truncate long lines for display\n",
    "                display_line = line[:100] + \"...\" if len(line) > 100 else line\n",
    "                display(Markdown(f\"**Line {i}:** `{display_line}`\"))\n",
    "                \n",
    "        except Exception as e:\n",
    "            display(Markdown(f\"‚ö†Ô∏è Could not read CSV preview: {e}\"))\n",
    "    \n",
    "    except Exception as e:\n",
    "        display(Markdown(f\"‚ùå **CSV conversion failed:** {e}\"))\n",
    "else:\n",
    "    display(Markdown(\"‚è≠Ô∏è **No embedding file to convert**\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## Summary & Next Steps\n\nüéâ **Congratulations!** You've successfully:\n\n1. ‚¨áÔ∏è Downloaded a real-world ontology (Cardiovascular Disease Ontology)\n2. ü§ñ Trained a Graph Neural Network on the ontology structure\n3. üìä Generated high-dimensional embeddings for all concepts\n4. üîç Inspected the rich metadata stored with embeddings\n5. ‚ûï‚ûñ Performed vector arithmetic operations\n6. üìÅ Converted between Parquet and CSV formats\n\n### üöÄ What You Can Do Next:\n\n- **Analyze similarities:** Use cosine similarity to find related cardiovascular concepts\n- **Cluster concepts:** Apply K-means or hierarchical clustering to discover disease patterns\n- **Visualize:** Create UMAP or t-SNE plots of the cardiovascular disease embedding space\n- **Cross-ontology mapping:** Train on CVDO, embed other medical ontologies\n- **Semantic search:** Find diseases similar to a query condition\n\n### üìö Learn More:\n\n- Check the project README for CLI tools and advanced usage\n- Explore the `parquet_tools.py` script for more utilities\n- Try different GNN architectures (GCN, GAT) and loss functions\n- Experiment with different embedding dimensions and training parameters"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### üßπ Cleanup (Optional)\n",
    "\n",
    "Run this cell if you want to remove the generated files:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Uncomment and run to clean up generated files\n# import os\n\n# files_to_remove = ['cvdo.owl', 'cvdo_model.pt', 'cvdo_embeddings.parquet', 'cvdo_embeddings.csv']\n\n# for filename in files_to_remove:\n#     if os.path.exists(filename):\n#         os.remove(filename)\n#         print(f\"üóëÔ∏è Removed {filename}\")\n#     else:\n#         print(f\"‚ö†Ô∏è {filename} not found\")\n\n# print(\"‚úÖ Cleanup complete!\")"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}